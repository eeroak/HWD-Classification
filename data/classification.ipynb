{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x104ff8f8070>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST Handwritten Digit Classification\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn               # to load neural network functionality\n",
    "import torch.nn.functional as nnF       # Adds efficiency\n",
    "from torch.utils.data import DataLoader # Data loading in batches\n",
    "from torchvision import datasets, transforms\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix # For evaluating results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "torch.manual_seed(2002) # setting seed for consistent results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: \\data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = transforms.ToTensor()\n",
    "#print(os.getcwd()) # For debugging :D lol folder problems\n",
    "train_data = datasets.MNIST(root='\\data', train=True, download=False, transform=transformer) # loading the training data\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: \\data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = datasets.MNIST(root='\\data', train=False, download=False, transform=transformer) # Loading the test data\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28]) \n",
      "Image Label: 6\n"
     ]
    }
   ],
   "source": [
    "image, label = train_data[18]\n",
    "print('Image shape:', image.shape, '\\nImage Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x104afad6410>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.reshape((28,28)), cmap=\"gray\") # Gray colormap for only one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing data loaders for batch data loading for training and testing sets\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MP(nn.Module): # MP = short for MultilayerPerceptron\n",
    "    # The input size is the flattened 2D-image array, from [[28,28]] -> [784] or smth\n",
    "    # Takes 120 inputs and has 84 neurons, output size is 10, since 0-9 is the range we are dealing with.\n",
    "    def __init__(self, input_size=784, output_size=10, layers=[120,84]):\n",
    "        super().__init__()\n",
    "        # With PyTorch, there is no need to create a separate input layer, it handles the input for you :)\n",
    "        self.hl1 = nn.Linear(input_size, layers[0])  # Hidden layer 1 for computation\n",
    "        self.hl2 = nn.Linear(layers[0], layers[1])   # Hidden layer 2   \n",
    "        self.ol = nn.Linear(layers[1], output_size) # Output layer\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = nnF.relu(self.hl1(X))\n",
    "        X = nnF.relu(self.hl2(X))\n",
    "        X = self.ol(X)\n",
    "        return nnF.log_softmax(X, dim=1) # Applying a softmax limit with a logarithm function\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP(\n",
      "  (hl1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (hl2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (ol): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MP()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing the model for trying to minimize loss throughtout iterations\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape at start: torch.Size([100, 1, 28, 28])\n",
      "Batch shape after flattening: torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(\"Batch shape at start:\", images.size())\n",
    "    break\n",
    "print(\"Batch shape after flattening:\", images.view(100, -1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "n_epochs = 10 # Number of epochs to train the model on\n",
    "\n",
    "model.train() # Preparing model for training\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Monitorin training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        # Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        data = data.view(data.shape[0], -1) # Reshaping the data\n",
    "        # Compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        loss = criteria(output, target)\n",
    "        # Compute gradient of the loss with respect to the model parameters\n",
    "        loss.backward()\n",
    "        # Perform a single parameter update\n",
    "        optimizer.step()\n",
    "        # Update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # Print training stats and calculate average loss between epochs\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss\n",
    "        ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
